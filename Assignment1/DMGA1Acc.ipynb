{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j9bt3Uh1Wdvy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score, roc_curve, roc_auc_score, plot_roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def runMetrics(trueVal,preds):\n",
        "  if len(set(trueVal))<=2:\n",
        "    print('Accuracy = ', accuracy_score(trueVal,preds))\n",
        "    print('Macro Precision = ', precision_score(trueVal,preds,average='macro'))\n",
        "    print('Micro Precision = ', precision_score(trueVal,preds,average='micro'))\n",
        "    print('Weighted Precision = ', precision_score(trueVal,preds,average='weighted'))\n",
        "    print('Macro Recall = ', recall_score(trueVal,preds,average='macro'))\n",
        "    print('Micro Recall = ', recall_score(trueVal,preds,average='micro'))\n",
        "    print('Weighted Recall = ', recall_score(trueVal,preds,average='weighted'))\n",
        "    print('Macro F1 = ', f1_score(trueVal,preds,average='macro'))\n",
        "    print('Micro F1 = ', f1_score(trueVal,preds,average='micro'))\n",
        "    print('Weighted F1 = ', f1_score(trueVal,preds,average='weighted'))\n",
        "    print('\\nClassification Report\\n', classification_report(trueVal,preds))\n",
        "  else:\n",
        "    print('Accuracy = ', accuracy_score(trueVal,preds))\n",
        "    print('Macro Precision = ', precision_score(trueVal,preds,average='macro'))\n",
        "    print('Micro Precision = ', precision_score(trueVal,preds,average='micro'))\n",
        "    print('Weighted Precision = ', precision_score(trueVal,preds,average='weighted'))\n",
        "    print('Macro Recall = ', recall_score(trueVal,preds,average='macro'))\n",
        "    print('Micro Recall = ', recall_score(trueVal,preds,average='micro'))\n",
        "    print('Weighted Recall = ', recall_score(trueVal,preds,average='weighted'))\n",
        "    print('Macro F1 = ', f1_score(trueVal,preds,average='macro'))\n",
        "    print('Micro F1 = ', f1_score(trueVal,preds,average='micro'))\n",
        "    print('Weighted F1 = ', f1_score(trueVal,preds,average='weighted'))\n",
        "    print('\\nClassification Report\\n', classification_report(trueVal,preds))"
      ],
      "metadata": {
        "id": "q5cmA4aCXF18"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runMetrics([1],[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hspuf4jwbnR7",
        "outputId": "f38abff3-d41c-4a8b-b93a-82208a7d3965"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  1.0\n",
            "Macro Precision =  1.0\n",
            "Micro Precision =  1.0\n",
            "Weighted Precision =  1.0\n",
            "Macro Recall =  1.0\n",
            "Micro Recall =  1.0\n",
            "Weighted Recall =  1.0\n",
            "Macro F1 =  1.0\n",
            "Micro F1 =  1.0\n",
            "Weighted F1 =  1.0\n",
            "\n",
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         1\n",
            "   macro avg       1.00      1.00      1.00         1\n",
            "weighted avg       1.00      1.00      1.00         1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TlhU1Gxjbts9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}